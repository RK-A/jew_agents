import json
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage
# from trend_agent.utils.state import TrendState
# from trend_agent.utils.tools import extract_keywords_tool, calculate_metrics_tool
import os
from .state import TrendState
from .tools import extract_keywords_tool, calculate_metrics_tool
base_url = os.getenv("OPENAI_BASE_URL", "http://localhost:1234/v1")
api_key = os.getenv("OPENAI_API_KEY", "lm-studio")


llm = ChatOpenAI(
    base_url=base_url,
    api_key=api_key,
    model="lmstudio-community/Qwen3-4B-Instruct-2507-GGUF",  # –ò–º—è –¥–ª—è –ª–æ–≥–æ–≤
    temperature=0.7,               # Qwen –ª—é–±–∏—Ç —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É —á—É—Ç—å –≤—ã—à–µ 0 –¥–ª—è –∫—Ä–µ–∞—Ç–∏–≤–∞
)
# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ (API –∫–ª—é—á –ø–æ–¥—Ç—è–Ω–µ—Ç—Å—è –∏–∑ env)
# llm = ChatOpenAI(model="gpt-4o", temperature=0)

def extraction_node(state: TrendState):
    print("--- [1/4] Extracting Keywords ---")
    keywords = extract_keywords_tool(state["content"])
    return {"extracted_keywords": keywords}


def analysis_node(state: TrendState):
    print("--- [2/4] Analyzing Trends (LLM) ---")
    content = state["content"]
    keywords = state["extracted_keywords"]
    
    # 1. –ò—Å–ø–æ–ª—å–∑—É–µ–º –ü–û–õ–ù–´–ô –ø—Ä–æ–º–ø—Ç –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ trend_agent.py
    prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–µ–∫—Å—Ç –æ –º–æ–¥–µ –∏ –∏–∑–≤–ª–µ–∫–∏ —é–≤–µ–ª–∏—Ä–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã.
    
    –ù–∞–π–¥–µ–Ω–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞:
    {json.dumps(keywords, indent=2, ensure_ascii=False)}
    
    –¢–µ–∫—Å—Ç:
    {content[:2000]}...
    
    –û–ø—Ä–µ–¥–µ–ª–∏:
    1. –¢–æ–ø-5 –º–æ–¥–Ω—ã—Ö —Å—Ç–∏–ª–µ–π
    2. –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã
    3. –¢—Ä–µ–Ω–¥–æ–≤—ã–µ —Ü–≤–µ—Ç–∞
    4. –£–ø–æ–º—è–Ω—É—Ç—ã–µ –¥–∏–∑–∞–π–Ω–µ—Ä—ã/–±—Ä–µ–Ω–¥—ã
    5. –°–µ–∑–æ–Ω–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑
    
    –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ:
    {{
        "trending_styles": ["—Å—Ç–∏–ª—å1", ...],
        "popular_materials": ["–º–∞—Ç–µ—Ä–∏–∞–ª1", ...],
        "trending_colors": ["—Ü–≤–µ—Ç1", ...],
        "mentioned_designers": ["–∏–º—è", ...],
        "seasonal_forecast": "–æ–ø–∏—Å–∞–Ω–∏–µ —Å–µ–∑–æ–Ω–∞"
    }}

    JSON:"""
    
    response = llm.invoke([
        SystemMessage(content="–¢—ã —ç–∫—Å–ø–µ—Ä—Ç-–∞–Ω–∞–ª–∏—Ç–∏–∫ –º–æ–¥—ã. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON."), 
        HumanMessage(content=prompt)
    ])
    
    # 2. –£–ª—É—á—à–µ–Ω–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ JSON (–∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ + –∑–∞—â–∏—Ç–∞ –æ—Ç markdown)
    txt = response.content.strip()
    # –£–¥–∞–ª—è–µ–º ```json –∏ ```
    if txt.startswith("```json"):
        txt = txt.split("```json").split("```").strip()[1]
    elif txt.startswith("```"):
        txt = txt.split("```")[6].split("```")[0].strip()
        
    try:
        trends = json.loads(txt)
    except Exception as e:
        print(f"JSON Parsing Error: {e}. Using fallback logic.")
        # Fallback –ª–æ–≥–∏–∫–∞ –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞: –±–µ—Ä–µ–º —Ç–æ–ø—ã –∏–∑ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        trends = {
            "trending_styles": [kw["keyword"] for kw in keywords.get("styles", [])[:5]],
            "popular_materials": [kw["keyword"] for kw in keywords.get("materials", [])[:5]],
            "trending_colors": [kw["keyword"] for kw in keywords.get("colors", [])[:3]],
            "mentioned_designers": [],
            "seasonal_forecast": "Unable to determine from LLM error"
        }
        
    return {"trends": trends}


def calculation_node(state: TrendState):
    print("--- [3/4] Calculating Metrics ---")
    scores, emerging, recs = calculate_metrics_tool(state["trends"], state["extracted_keywords"])
    return {
        "trend_scores": scores,
        "emerging_trends": emerging,
        "recommendations": recs
    }

def reporting_node(state: TrendState):
    print("--- [4/4] Writing Report ---")
    
    # –ö–æ–Ω—Ç–µ–∫—Å—Ç –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ _generate_trend_report
    context = f"""
    === –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ ===
    {json.dumps(state['extracted_keywords'], indent=2, ensure_ascii=False)}
    
    === –í—ã—è–≤–ª–µ–Ω–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã ===
    {json.dumps(state['trends'], indent=2, ensure_ascii=False)}
    
    === –ù–æ–≤—ã–µ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è ===
    {json.dumps(state['emerging_trends'], indent=2, ensure_ascii=False)}
    
    === –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ ===
    {json.dumps(state['recommendations'], indent=2, ensure_ascii=False)}
    """
    
    prompt = f"""–¢—ã ‚Äî —Å—Ç–∞—Ä—à–∏–π –∞–Ω–∞–ª–∏—Ç–∏–∫ –º–æ–¥—ã, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ —é–≤–µ–ª–∏—Ä–Ω—ã—Ö –∏–∑–¥–µ–ª–∏—è—Ö –∏ –∞–∫—Å–µ—Å—Å—É–∞—Ä–∞—Ö.
    –ù–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–≤–µ–¥–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Å—Ñ–æ—Ä–º–∏—Ä—É–π –ø–æ–¥—Ä–æ–±–Ω—ã–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –æ —Ç—Ä–µ–Ω–¥–∞—Ö:
    {context}
    
    –û—Ç—Ä—ã–≤–æ–∫ –∏–∑ —Ä–µ–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç—å–∏:
    {state['content'][:1000]}...
    
    –¢–†–ï–ë–û–í–ê–ù–ò–Ø –ö –û–¢–ß–ï–¢–£ (Markdown):
    
    # 1. –†–µ–∑—é–º–µ
    –ö—Ä–∞—Ç–∫–æ (3-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è): –≥–ª–∞–≤–Ω–∞—è –∏–¥–µ—è —Å–µ–∑–æ–Ω–∞, –∫–ª—é—á–µ–≤–æ–π –¥—Ä–∞–π–≤–µ—Ä –ø—Ä–æ–¥–∞–∂.
    
    # 2. –ê–Ω–∞–ª–∏–∑ –¢—Ä–µ–Ω–¥–æ–≤ (–¢–∞–±–ª–∏—Ü–∞)
    –°–æ–∑–¥–∞–π Markdown-—Ç–∞–±–ª–∏—Ü—É —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏: "–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ", "–ö–ª—é—á–µ–≤—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã", "–°—Ç–∞—Ç—É—Å" (–†–∞—Å—Ç—É—â–∏–π/–ü–∏–∫–æ–≤—ã–π/–£–≥–∞—Å–∞—é—â–∏–π).
    –û–ø–∏—à–∏ –°—Ç–∏–ª–∏, –ú–∞—Ç–µ—Ä–∏–∞–ª—ã –∏ –¶–≤–µ—Ç–∞.
    
    # 3. –¢–æ–≤–∞—Ä–Ω–∞—è –ú–∞—Ç—Ä–∏—Ü–∞ (–ö–∞—Ç–µ–≥–æ—Ä–∏–∏)
    –ö–∞–∫–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —É–∫—Ä–∞—à–µ–Ω–∏–π (–ö–æ–ª—å—Ü–∞, –°–µ—Ä—å–≥–∏...) —Å–µ–π—á–∞—Å –ª–∏–¥–∏—Ä—É—é—Ç –ø–æ —É–ø–æ–º–∏–Ω–∞–µ–º–æ—Å—Ç–∏? –î–∞–π –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é —Ü–∏—Ñ—Ä–∞–º –∏–∑ Share of Voice.
    
    # 4. Action Plan (–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏)
    –ü—Ä–µ–≤—Ä–∞—Ç–∏ JSON-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –≤ —Å–≤—è–∑–Ω—ã–π —Ç–µ–∫—Å—Ç. –†–∞–∑–¥–µ–ª–∏ –Ω–∞:
    * üì¶ –ó–∞–∫—É–ø–∫–∏ (–ß—Ç–æ –ø–æ–∫—É–ø–∞—Ç—å –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å)
    * üé® –î–∏–∑–∞–π–Ω (–ß—Ç–æ —Ä–∞–∑—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å)
    * üì¢ –ú–∞—Ä–∫–µ—Ç–∏–Ω–≥ (–û —á–µ–º –≥–æ–≤–æ—Ä–∏—Ç—å —Å –∫–ª–∏–µ–Ω—Ç–æ–º)
    
    # 5. –ò–Ω—Å–∞–π—Ç—ã
    –ï—Å–ª–∏ –≤ –¥–∞–Ω–Ω—ã—Ö –µ—Å—Ç—å –∏–º–µ–Ω–∞ –¥–∏–∑–∞–π–Ω–µ—Ä–æ–≤ –∏–ª–∏ —Å–µ–∑–æ–Ω–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑, –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —É–ø–æ–º—è–Ω–∏ –∏—Ö –∫–∞–∫ –∞—Ä–≥—É–º–µ–Ω—Ç—ã –¥–ª—è –∞–≤—Ç–æ—Ä–∏—Ç–µ—Ç–Ω–æ—Å—Ç–∏.
    
    –°—Ç–∏–ª—å –ø–∏—Å—å–º–∞: –î–µ–ª–æ–≤–æ–π, –ª–∞–∫–æ–Ω–∏—á–Ω—ã–π, –±–µ–∑ –≤–æ–¥—ã. –ò—Å–ø–æ–ª—å–∑—É–π –∂–∏—Ä–Ω—ã–π —à—Ä–∏—Ñ—Ç –¥–ª—è –∞–∫—Ü–µ–Ω—Ç–æ–≤.
    """
    
    response = llm.invoke([HumanMessage(content=prompt)])
    return {"report": response.content}

