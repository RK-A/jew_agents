# AI Jewelry Consultation System - Environment Variables Configuration
# Copy this file to .env and fill in your actual values

# =============================================================================
# LLM Provider Configuration
# =============================================================================
# Choose LLM provider: "openai" or "gigachat"
LLM_PROVIDER=openai

# Model name for chosen provider
# OpenAI: gpt-4, gpt-3.5-turbo, gpt-4-turbo
# GigaChat: GigaChat:latest, GigaChat-Pro
LLM_MODEL=gpt-4

# API key for LLM provider
LLM_API_KEY=your_openai_api_key_here

# Temperature for LLM responses (0.0 - 1.0)
# Lower = more focused/deterministic, Higher = more creative
LLM_TEMPERATURE=0.7

# =============================================================================
# Database Configuration
# =============================================================================
# PostgreSQL connection URL
# Format: postgresql+asyncpg://user:password@host:port/database
POSTGRES_URL=postgresql+asyncpg://postgres:password@localhost:5432/jewelry

# =============================================================================
# Qdrant Vector Database Configuration
# =============================================================================
# Qdrant server URL
QDRANT_URL=http://localhost:6333

# Collection name for jewelry products
QDRANT_COLLECTION=jewelry_products

# =============================================================================
# Embeddings Configuration
# =============================================================================
# Embedding model to use
# Options: 
#   - text-embedding-3-small (OpenAI, recommended)
#   - text-embedding-3-large (OpenAI, more accurate)
#   - multilingual-e5-base (HuggingFace, free)
#   - gigachat (GigaChat embeddings)
EMBEDDING_MODEL=text-embedding-3-small

# API key for embeddings (if using OpenAI)
# Can be same as LLM_API_KEY for OpenAI
EMBEDDING_API_KEY=your_embedding_api_key_here

# =============================================================================
# API Server Configuration
# =============================================================================
# Host to bind the API server
API_HOST=0.0.0.0

# Port for API server
API_PORT=8000

# =============================================================================
# Data Generation Configuration
# =============================================================================
# Automatically fill database with test data on first startup
# Set to "true" for quick start, "false" for production
AUTO_FILL_DATA=false

# Number of products to generate (if AUTO_FILL_DATA=true)
DEFAULT_PRODUCTS_COUNT=80

# Number of users/customer profiles to generate
DEFAULT_USERS_COUNT=25

# Number of consultation records to generate
DEFAULT_CONSULTATIONS_COUNT=40

# =============================================================================
# Quick Start Instructions
# =============================================================================
# 1. Copy this file to .env:
#    cp env.example .env
#
# 2. Fill in your API keys above
#
# 3. Start services with Docker Compose:
#    docker-compose up -d
#
# 4. Initialize database and fill with test data:
#    python scripts/manage_data.py init
#    python scripts/manage_data.py fill --products 80 --users 25
#    python scripts/manage_data.py sync
#
# 5. Or simply set AUTO_FILL_DATA=true and restart
#
# 6. Check status:
#    python scripts/manage_data.py status
#
# 7. Access API documentation:
#    http://localhost:8000/docs
#
# =============================================================================

