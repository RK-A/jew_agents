# AI Jewelry Consultation System - Environment Variables Configuration
# Copy this file to .env and fill in your actual values

# =============================================================================
# LLM Provider Configuration
# =============================================================================
# Choose LLM provider: "openai" or "gigachat"
LLM_PROVIDER=openai

# Model name for chosen provider
# OpenAI: gpt-4, gpt-3.5-turbo, gpt-4-turbo
# GigaChat: GigaChat:latest, GigaChat-Pro
LLM_MODEL=gpt-4

# API key for LLM provider
LLM_API_KEY=your_openai_api_key_here

# Base URL for LLM provider (optional, for custom endpoints)
# OpenAI: leave empty or use default
# GigaChat: https://gigachat.devices.sberbank.ru/api/v1
LLM_BASE_URL=

# Temperature for LLM responses (0.0 - 1.0)
# Lower = more focused/deterministic, Higher = more creative
LLM_TEMPERATURE=0.7

# =============================================================================
# Database Configuration
# =============================================================================
# PostgreSQL connection URL
# Format: postgresql+asyncpg://user:password@host:port/database
POSTGRES_URL=postgresql+asyncpg://postgres:password@localhost:5432/jewelry

# =============================================================================
# Qdrant Vector Database Configuration
# =============================================================================
# Qdrant server URL
QDRANT_URL=http://localhost:6333

# Collection name for jewelry products
QDRANT_COLLECTION=jewelry_products

# =============================================================================
# Embeddings Configuration (LangChain)
# =============================================================================
# Embedding provider: "openai", "huggingface", "gigachat", or "local"
EMBEDDING_PROVIDER=openai

# Embedding model to use (depends on provider)
# 
# OpenAI models:
#   - text-embedding-3-small (1536 dims, recommended, fast & cheap)
#   - text-embedding-3-large (3072 dims, most accurate)
#   - text-embedding-ada-002 (1536 dims, legacy)
#
# HuggingFace models (free, runs locally):
#   - intfloat/multilingual-e5-base (768 dims, multilingual)
#   - intfloat/multilingual-e5-small (384 dims, faster)
#   - intfloat/multilingual-e5-large (1024 dims, more accurate)
#
# GigaChat models:
#   - gigachat-embeddings (1024 dims, Yandex GigaChat)
#
# Local API models (via LM Studio, LocalAI, etc.):
#   - text-embedding-snowflake-arctic-embed-m-v1.5 (768 dims)
#   - text-embedding-nomic-embed-text-v1.5 (768 dims)
#   - all-MiniLM-L6-v2 (384 dims)
#   - all-mpnet-base-v2 (768 dims)
#
EMBEDDING_MODEL=text-embedding-3-small

# API key for embeddings (required for OpenAI and GigaChat)
# For OpenAI: can be same as LLM_API_KEY
# For HuggingFace: not required (models run locally)
# For GigaChat: use GigaChat API credentials
# For Local API: not required
EMBEDDING_API_KEY=your_embedding_api_key_here

# Base URL for local embedding API (required for EMBEDDING_PROVIDER=local)
# Examples:
#   - LM Studio: http://127.0.0.1:1234/v1
#   - LocalAI: http://localhost:8080/v1
#   - Custom: http://your-server:port/v1
EMBEDDING_BASE_URL=

# =============================================================================
# API Server Configuration
# =============================================================================
# Host to bind the API server
API_HOST=0.0.0.0

# Port for API server
API_PORT=8000

# =============================================================================
# Agent Configuration
# =============================================================================
# Language for agent responses: "en" (English), "ru" (Russian), or "auto" (match user's language)
AGENT_LANGUAGE=auto

# Custom system prompts for agents (optional)
# If not set, default prompts will be used
# Use these to customize agent behavior without code changes

# Consultant Agent custom prompt (optional)
# AGENT_CUSTOM_PROMPT_CONSULTANT=Ты эксперт-консультант по ювелирным изделиям. Всегда будь вежлив и профессионален.

# Analysis Agent custom prompt (optional)
# AGENT_CUSTOM_PROMPT_ANALYSIS=You are a senior market analyst specializing in luxury goods.

# Trend Agent custom prompt (optional)
# AGENT_CUSTOM_PROMPT_TREND=You are a fashion trend forecaster with expertise in jewelry trends.

# =============================================================================
# Data Generation Configuration
# =============================================================================
# Automatically fill database with test data on first startup
# Set to "true" for quick start, "false" for production
AUTO_FILL_DATA=false

# Number of products to generate (if AUTO_FILL_DATA=true)
DEFAULT_PRODUCTS_COUNT=80

# Number of users/customer profiles to generate
DEFAULT_USERS_COUNT=25

# Number of consultation records to generate
DEFAULT_CONSULTATIONS_COUNT=40

# =============================================================================
# Example Configurations for Different Setups
# =============================================================================

# --- OpenAI Setup (Recommended for Production) ---
# LLM_PROVIDER=openai
# LLM_MODEL=gpt-4
# LLM_API_KEY=sk-...
# EMBEDDING_PROVIDER=openai
# EMBEDDING_MODEL=text-embedding-3-small
# EMBEDDING_API_KEY=sk-...  # Can be same as LLM_API_KEY

# --- GigaChat Setup (Yandex) ---
# LLM_PROVIDER=gigachat
# LLM_MODEL=GigaChat:latest
# LLM_API_KEY=your_gigachat_credentials
# LLM_BASE_URL=https://gigachat.devices.sberbank.ru/api/v1
# EMBEDDING_PROVIDER=gigachat
# EMBEDDING_MODEL=gigachat-embeddings
# EMBEDDING_API_KEY=your_gigachat_credentials

# --- Local/Free Setup (HuggingFace + OpenAI LLM) ---
# LLM_PROVIDER=openai
# LLM_MODEL=gpt-3.5-turbo
# LLM_API_KEY=sk-...
# EMBEDDING_PROVIDER=huggingface
# EMBEDDING_MODEL=intfloat/multilingual-e5-base
# EMBEDDING_API_KEY=  # Not required for HuggingFace

# --- Local API Setup (LM Studio / LocalAI) ---
# LLM_PROVIDER=openai
# LLM_MODEL=gpt-3.5-turbo
# LLM_API_KEY=sk-...
# EMBEDDING_PROVIDER=local
# EMBEDDING_MODEL=text-embedding-snowflake-arctic-embed-m-v1.5
# EMBEDDING_API_KEY=  # Not required for local
# EMBEDDING_BASE_URL=http://127.0.0.1:1234/v1

# =============================================================================
# Quick Start Instructions
# =============================================================================
# 1. Copy this file to .env:
#    cp env.example .env
#
# 2. Fill in your API keys and choose your providers above
#
# 3. Install dependencies:
#    pip install -r requirements.txt
#
# 4. Start services with Docker Compose:
#    docker-compose up -d
#
# 5. Initialize database and Qdrant:
#    python scripts/manage_data.py init
#
# 6. Fill with test data:
#    python scripts/manage_data.py fill --products 80 --users 25
#    python scripts/manage_data.py sync
#
# 7. Or simply set AUTO_FILL_DATA=true and restart the app
#
# 8. Check status:
#    python scripts/manage_data.py status
#
# 9. Access API documentation:
#    http://localhost:8000/docs
#
# =============================================================================
# Notes
# =============================================================================
# - LangChain embeddings are now used for RAG system
# - Embedding dimensions are automatically detected from model name
# - HuggingFace models download on first use (may take time)
# - OpenAI embeddings require internet connection and API key
# - GigaChat requires Russian IP address or VPN
# =============================================================================

